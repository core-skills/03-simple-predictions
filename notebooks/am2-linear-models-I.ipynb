{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile-Quantile Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10000 random numbers from a normal distribution with 0 mean and standard deviation 5\n",
    "sample = np.random.normal(0, 5, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the samples to a theoretical normal distribution\n",
    "sm.qqplot(sample,line='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes our data does not look strictly linear. In some cases, we can transform our data so that we can easily apply linear regression. To understand various transforms, we will create a data series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,100).reshape(-1,1)\n",
    "y = np.array([(i**2)+(10*i)*(np.sin(i)+1) for i in x]) # + np.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(y,line='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data does not look strictly linear, but let's go ahead and fit a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=100)\n",
    "model = LinearRegression() # y=m*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R^2: \",model.score(x_test, y_test))\n",
    "print(\"Slope: \", model.coef_)\n",
    "print(\"Intercept: \", model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(x_test)\n",
    "res_test = pred_test - y_test\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(x_test,y_test,label='Data')\n",
    "plt.plot(x_test,pred_test,label='Fit')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.scatter(x_test,res_test)\n",
    "plt.title(\"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good! And the coefficient of determiniation is close to 1. Looks like we have a nice model. Let's plot the model for all of the input data (x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x)\n",
    "res = pred - y\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(x,pred,label='Fit')\n",
    "plt.scatter(x,y,label='Data')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.scatter(x,res)\n",
    "plt.title(\"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Look at those residuals. I don't think the model we have obtained is great. Looking at the residuals, the error seems to increase as the value of x increases. This could be a sign of heteroscedasticity, which violates one of our assumptions.\n",
    "\n",
    "Let's try to transform the data (y) and see if this helps make the residuals more normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reciprocal Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not very useful for the current example, a reciprocal transforms can be useful for changing the scale of the data if there is a need to make the values more manageable and understandable. It can be particularly useful with data expressed as ratios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_rec = 1/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,transform_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In nature, various phenomena have been shown to exhibit an exponential relationship. In the physical sciences, the exponential function shows up often enough that when we think about transformations the log transform should come to mind. The log transform is a special case of a change of base transform. From looking at the residuals, the errors are showing an interesting pattern that we want to try and account for in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_log = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,transform_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(transform_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(x,y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=100)\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    print(\"R^2: \",model.score(x_test, y_test))\n",
    "    print(\"Slope: \", model.coef_)\n",
    "    print(\"Intercept: \", model.intercept_)\n",
    "    pred_test = model.predict(x_test)\n",
    "    res_test = pred_test - y_test\n",
    "\n",
    "    if(x.shape[1] > 1):\n",
    "        sort_axis = operator.itemgetter(0)\n",
    "        sorted_zip = sorted(zip(x_test[:,1],pred_test), key=sort_axis)\n",
    "        xplt, yplt = zip(*sorted_zip)\n",
    "    else:\n",
    "        xplt = x_test\n",
    "        yplt = pred_test\n",
    "        \n",
    "    plt.subplot(121)\n",
    "    plt.scatter(xplt,y_test,label='Test data')\n",
    "    plt.plot(xplt,yplt,label='Model fit',color='red',linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(xplt,res_test)\n",
    "    plt.title(\"Residuals (test data)\")\n",
    "    plt.show()\n",
    "\n",
    "    pred = model.predict(x)\n",
    "    res = pred - y\n",
    "\n",
    "    if(x.shape[1] > 1):\n",
    "        sort_axis = operator.itemgetter(0)\n",
    "        sorted_zip = sorted(zip(x[:,1],pred), key=sort_axis)\n",
    "        xplt, yplt = zip(*sorted_zip)\n",
    "    else:\n",
    "        xplt = x\n",
    "        yplt = pred\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.plot(xplt,yplt,label='Fit',color='red',linewidth=2)\n",
    "    plt.scatter(xplt,y,label='Data')\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(xplt,res)\n",
    "    plt.title(\"Residuals\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it does not look like a log transform is a good idea. It shifted the skew of the data distribution and did not address the underlying issue with the trend still seen in the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square Root Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a square root transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_sqrt = np.sqrt(y) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_model = make_model(x,transform_sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! I would say this looks better. The errors look relatively uniform and centered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to do this is via the [preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) toolkit in scikit-learn. Just for fun, let's make our own square root transformer (which could be used in a scikit-learn pipeline workflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "transformer = preprocessing.FunctionTransformer(np.sqrt, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.transform(y)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(transformer.transform(y) - transform_sqrt) # to convince ourselves this is yielding the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-Cox Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Box-Cox is a general power transform. The log and square root transforms are specific cases of a Box-Cox transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_transformer = preprocessing.PowerTransformer(method='box-cox', standardize=True).fit(y)\n",
    "boxcox_transformer.lambdas_ # this is the exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_boxcox = boxcox_transformer.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcoxmodel = make_model(x,y_boxcox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit here is perhaps not as good as the square root transform, but would help us hone in on the correct transform to use if we did not know where to start. When you have time, explore some of the preprocessing transforms that might be of use such as the [quantile](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.quantile_transform.html#sklearn.preprocessing.quantile_transform) transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If power transforms are not sufficient, we can look at introducing additional terms into our linear model and using polynomial regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial = preprocessing.PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel = make_model(x_poly,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it visually looks like the polynomial has a better fit to the data, the residuals show a different pattern. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, based on all the linear models that we have fit to transformed data it seems the one with the square root transform has the best fit and satisfies the assumptions so that we have confidence in using the model. Applying more complex data transformations, via Box-Cox, and using a polynomial to fit the data did not address the underlying issues we sought out to address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will look at the use of resampling of data. Let's load data on the duration of trips from bicyle users from [Capital Bikeshare](https://www.capitalbikeshare.com/system-data) available [here](https://s3.amazonaws.com/capitalbikeshare-data/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.path.abspath('..'), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = os.path.join(data_folder,'202001-capitalbikeshare-tripdata.csv')\n",
    "bikes = pd.read_csv(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.plot('Start date','Duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! Let's try to sample the data at a more meaningful level. The first thing we need to do is ensure that the dataframe columns are appropriately typed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes['Start date']= pd.to_datetime(bikes['Start date'])\n",
    "bikes['End date']= pd.to_datetime(bikes['End date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.plot('Start date','Duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.set_index('Start date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bikes.plot('Start date','Duration')\n",
    "daily_summary = pd.DataFrame()\n",
    "daily_summary['Duration'] = bikes.Duration.resample('D').mean()\n",
    "daily_summary.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weekly_summary = pd.DataFrame()\n",
    "weekly_summary['Duration'] = bikes.Duration.resample('W',label='right').mean()\n",
    "weekly_summary.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By resampling the data, we can now get a better idea of the average length of rides from bicycle riders for the month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling and fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our toy example. Let's treat it like a set of timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['date'] = pd.date_range(start='1/1/2019', end='12/31/2019', periods=len(y))\n",
    "df['y'] = y\n",
    "df.set_index('date', inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_summary = pd.DataFrame()\n",
    "monthly_summary['y'] = df.y.resample('M',label='right').mean()\n",
    "monthly_summary.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_summary.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_summary['date_delta'] = (monthly_summary['date'] - monthly_summary['date'].min()) / np.timedelta64(1,'D')\n",
    "monthly_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newx = np.array(monthly_summary['date_delta']).reshape(-1, 1)\n",
    "month_model = make_model(newx,monthly_summary['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_model(newx, np.sqrt(monthly_summary['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
